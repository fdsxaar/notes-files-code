CHAPTER 9
Consistency and Consensus

In this chapter, we will talk about some examples of algorithms and protocols for
building fault-tolerant distributed systems

The best way of building fault-tolerant systems is to find some general-purpose
abstractions with useful guarantees, implement them once, and then let applications
rely on those guarantees.

one of the most important abstractions for distributed systems is consensus:

But first we first
need to explore the range of guarantees and abstractions that can be provided in a
distributed system

We need to understand the scope of what can and cannot be done

1.一致性保证 Consistency Guarantees
Most replicated databases provide at least eventual consistency, which means that if
you stop writing to the database and wait for some unspecified length of time, then
eventually all read requests will return the same value [1]. In other words, the inconsistency
is temporary, and it eventually resolves itself (assuming that any faults in the
network are also eventually repaired). A better name for eventual consistency may be
convergence, as we expect all replicas to eventually converge to the same value [2].

However, this is a very weak guarantee—it doesn’t say anything about when the replicas
will converge.

When working with a database that provides only weak guarantees, you need to be
constantly aware of its limitations and not accidentally assume too much. Bugs are
often subtle and hard to find by testing, because the application may work well most
of the time. The edge cases of eventual consistency only become apparent when there
is a fault in the system (e.g., a network interruption) or at high concurrency.

transaction isolation is primarily about avoiding race conditions due to
concurrently executing transactions, whereas distributed consistency is mostly about
coordinating the state of replicas in the face of delays and faults

2.可线性化 Linearizability 
linearizability [6] (also known as atomic consistency [7], strong
consistency, immediate consistency, or external consistency [8]).

But the basic idea is to make a system appear as if there were only one copy of the data,
and all operations on it are atomic

In a linearizable system, as soon as one client successfully completes a write, all clients
reading from the database must be able to see the value just written. Maintaining
the illusion of a single copy of the data means guaranteeing that the value read is the
most recent, up-to-date value, and doesn’t come from a stale cache or replica.

2.1 如何使系统可线性化 What Makes a System Linearizable?
The basic idea behind linearizability is simple: to make a system appear as if there is
only a single copy of the data.

In the distributed systems literature, x is called a register—in
practice, it could be one key in a key-value store, one row in a relational database, or
one document in a document database, for example.

Linearizability Versus Serializability
//可串行化是事务隔离级别的语义
Serializability
Serializability is an isolation property of transactions, where every transaction
may read and write multiple objects (rows, documents, records)—see “Single-
Object and Multi-Object Operations” on page 228. It guarantees that transactions
behave the same as if they had executed in some serial order (each
transaction running to completion before the next transaction starts). It is okay
for that serial order to be different from the order in which transactions were
actually run [12].

//可线性化是分布式系统层面的语义
Linearizability
Linearizability is a recency guarantee on reads and writes of a register (an individual
object). It doesn’t group operations together into transactions, so it does
not prevent problems such as write skew (see “Write Skew and Phantoms” on
page 246), unless you take additional measures such as materializing conflicts
(see “Materializing conflicts” on page 251).

A database may provide both serializability and linearizability, and this combination
is known as strict serializability or strong one-copy serializability (strong-1SR) [4, 13].
Implementations of serializability based on two-phase locking (see “Two-Phase Locking
(2PL)” on page 257) or actual serial execution (see “Actual Serial Execution” on
page 252) are typically linearizable.

However, serializable snapshot isolation (see “Serializable Snapshot Isolation (SSI)”
on page 261) is not linearizable: by design, it makes reads from a consistent snapshot,
to avoid lock contention between readers and writers. The whole point of a consistent
snapshot is that it does not include writes that are more recent than the snapshot, and
thus reads from the snapshot are not linearizable.

2.2 依赖可线性化 Relying on Linearizability
锁与领导者选举 Locking and leader election
A system that uses single-leader replication needs to ensure that there is indeed only
one leader, not several (split brain). One way of electing a leader is to use a lock: every
node that starts up tries to acquire the lock, and the one that succeeds becomes the
leader [14]. No matter how this lock is implemented, it must be linearizable: all nodes
must agree which node owns the lock; otherwise it is useless.

Coordination services like Apache ZooKeeper [15] and etcd [16] are often used to
implement distributed locks and leader election. They use consensus algorithms to
implement linearizable operations in a fault-tolerant way (we discuss such algorithms
later in this chapter, in “Fault-Tolerant Consensus” on page 364).iii There are still
many subtle details to implementing locks and leader election correctly (see for
example the fencing issue in “The leader and the lock” on page 301), and libraries like
Apache Curator [17] help by providing higher-level recipes on top of ZooKeeper.
However, a linearizable storage service is the basic foundation for these coordination
tasks.

Distributed locking is also used at a much more granular level in some distributed
databases, such as Oracle Real Application Clusters (RAC) [18]. RAC uses a lock per
disk page, with multiple nodes sharing access to the same disk storage system. Since
these linearizable locks are on the critical path of transaction execution, RAC deployments
usually have a dedicated cluster interconnect network for communication
between database nodes.

注：
Strictly speaking, ZooKeeper and etcd provide linearizable writes, but reads may be stale, since by default
they can be served by any one of the replicas. You can optionally request a linearizable read: etcd calls this a
quorum read [16], and in ZooKeeper you need to call sync() before the read [15]; see “Implementing linearizable
storage using total order broadcast” on page 350.

约束与唯一性保证 Constraints and uniqueness guarantees
用户名与电子邮件

跨通道时间依赖 Cross-channel timing dependencies
The linearizability violation
was only noticed because there was an additional communication channel in the
system (Alice’s voice to Bob’s ears).

2.2 实现可线性化系统 Implementing Linearizable Systems
//实现可线性化要考虑容错 
Since linearizability essentially means “behave as though there is only a single copy of
the data, and all operations on it are atomic,” the simplest answer would be to really
only use a single copy of the data. However, that approach would not be able to tolerate
faults: if the node holding that one copy failed, the data would be lost, or at least
inaccessible until the node was brought up again.

The most common approach to making a system fault-tolerant is to use replication

Single-leader replication (potentially linearizable)
However, not every single-leader database is actually linearizable,
either by design (e.g., because it uses snapshot isolation) or due to
concurrency bugs [10].

Using the leader for reads relies on the assumption that you know for sure who
the leader is. As discussed in “The Truth Is Defined by the Majority” on page
300, it is quite possible for a node to think that it is the leader, when in fact it is
not—and if the delusional leader continues to serve requests, it is likely to violate
linearizability [20]. With asynchronous replication, failover may even lose committed
writes (see “Handling Node Outages” on page 156), which violates both
durability and linearizability.

Consensus algorithms (linearizable)
However, consensus protocols contain
measures to prevent split brain and stale replicas. Thanks to these details, consensus
algorithms can implement linearizable storage safely. This is how Zoo‐
Keeper [21] and etcd [22] work, for example

Multi-leader replication (not linearizable) 
Systems with multi-leader replication are generally not linearizable, because they
concurrently process writes on multiple nodes and asynchronously replicate
them to other node

Leaderless replication (probably not linearizable)
In summary, it is safest to assume that a leaderless system with Dynamo-style replication
does not provide linearizability.

2.3 线性化的成本 The Cost of Linearizability
//对与单个leader 写与线性化读要通过leader完成，leader与其他followers之间的网络若断开，
//就无法继续工作 
On the other hand, if single-leader replication is used, then the leader must be in one
of the datacenters. Any writes and any linearizable reads must be sent to the leader—
thus, for any clients connected to a follower datacenter, those read and write requests
must be sent synchronously over the network to the leader datacenter.
If the network between datacenters is interrupted in a single-leader setup, clients connected
to follower datacenters cannot contact the leader, so they cannot make any
writes to the database, nor any linearizable reads. They can still make reads from the
follower, but they might be stale (nonlinearizable). If the application requires linearizable
reads and writes, the network interruption causes the application to become
unavailable in the datacenters that cannot contact the leader.

CAP理论 The CAP theorem
CAP theorem [29, 30, 31, 32],

CAP was originally proposed as a rule of thumb, without precise definitions, with the
goal of starting a discussion about trade-offs in databases. At the time, many distributed
databases focused on providing linearizable semantics on a cluster of
machines with shared storage [18], and CAP encouraged database engineers to
explore a wider design space of distributed shared-nothing systems, which were more
suitable for implementing large-scale web services [37]. CAP deserves credit for this
culture shift—witness the explosion of new database technologies since the
mid-2000s (known as NoSQL).

//网络通畅时，可用性和一致性都能得到满足 
The Unhelpful CAP Theorem
CAP is sometimes presented as Consistency, Availability, Partition tolerance: pick 2
out of 3. Unfortunately, putting it this way is misleading [32] because network partitions
are a kind of fault, so they aren’t something about which you have a choice: they
will happen whether you like it or not [38].

At times when the network is working correctly, a system can provide both consistency
(linearizability) and total availability. When a network fault occurs, you have to
choose between either linearizability or total availability. Thus, a better way of phrasing
CAP would be either Consistent or Available when Partitioned [39]. A more reliable
network needs to make this choice less often, but at some point the choice is
inevitable.

In discussions of CAP there are several contradictory definitions of the term availability,
and the formalization as a theorem [30] does not match its usual meaning [40].
Many so-called “highly available” (fault-tolerant) systems actually do not meet CAP’s
idiosyncratic definition of availability. All in all, there is a lot of misunderstanding
and confusion around CAP, and it does not help us understand systems better, so
CAP is best avoided.

The CAP theorem as formally defined [30] is of very narrow scope: it only considers
one consistency model (namely linearizability) and one kind of fault (network partitions,
vi or nodes that are alive but disconnected from each other). It doesn’t say any‐thing about
 network delays, dead nodes, or other trade-offs. Thus, although CAP has
been historically influential, it has little practical value for designing systems [9, 40].
There are many more interesting impossibility results in distributed systems [41],
and CAP has now been superseded by more precise results [2, 42], so it is of mostly
historical interest today.

//要实现线性化，必须解决网络延迟问题，然而，实际情况是网络延迟高度不确定，所以，依赖于网络
//延迟的线性化也高度不确定，是正相关的关系 
线性化和网络延迟Linearizability and network delays
Although linearizability is a useful guarantee, surprisingly few systems are actually
linearizable in practice. For example, even RAM on a modern multi-core CPU is not
linearizable [43]: if a thread running on one CPU core writes to a memory address,
and a thread on another CPU core reads the same address shortly afterward, it is not
guaranteed to read the value written by the first thread (unless a memory barrier or
fence [44] is used).

The reason for this behavior is that every CPU core has its own memory cache and
store buffer. Memory access first goes to the cache by default, and any changes are
asynchronously written out to main memory. Since accessing data in the cache is
much faster than going to main memory [45], this feature is essential for good performance
on modern CPUs. However, there are now several copies of the data (one
in main memory, and perhaps several more in various caches), and these copies are
asynchronously updated, so linearizability is lost.

Why make this trade-off? It makes no sense to use the CAP theorem to justify the
multi-core memory consistency model: within one computer we usually assume reliable
communication, and we don’t expect one CPU core to be able to continue operating
normally if it is disconnected from the rest of the computer. The reason for
dropping linearizability is performance, not fault tolerance.

The same is true of many distributed databases that choose not to provide linearizable
guarantees: they do so primarily to increase performance, not so much for fault
tolerance [46]. Linearizability is slow—and this is true all the time, not only during a
network fault.

Can’t we maybe find a more efficient implementation of linearizable storage? It
seems the answer is no: Attiya and Welch [47] prove that if you want linearizability,
the response time of read and write requests is at least proportional to the uncertainty
of delays in the network. In a network with highly variable delays, like most computer
networks (see “Timeouts and Unbounded Delays” on page 281), the response
time of linearizable reads and writes is inevitably going to be high. A faster algorithm
for linearizability does not exist, but weaker consistency models can be much faster,
so this trade-off is important for latency-sensitive systems. In Chapter 12 we will discuss
some approaches for avoiding linearizability without sacrificing correctness.

3.顺序保证 Ordering Guarantees
//捕获、追踪因果关系异常困难
3.1 顺序与因果关系 Ordering and Causality
If a system obeys the ordering imposed by causality, we say that it is causally consistent.

The causal order is not a total order
A total order allows any two elements to be compared, so if you have two elements,
you can always say which one is greater and which one is smaller

Linearizability
In a linearizable system, we have a total order of operations: if the system behaves
as if there is only a single copy of the data, and every operation is atomic, this
means that for any two operations we can always say which one happened first.

Causality
We said that two operations are concurrent if neither happened before the other
(see “The “happens-before” relationship and concurrency” on page 186). Put
another way, two events are ordered if they are causally related (one happened
before the other), but they are incomparable if they are concurrent. This means
that causality defines a partial order, not a total order: some operations are
ordered with respect to each other, but some are incomparable.

Therefore, according to this definition, there are no concurrent operations in a linearizable
datastore: there must be a single timeline along which all operations are
totally ordered.

Concurrency would mean that the timeline branches and merges again—and in this
case, operations on different branches are incomparable (i.e., concurrent).

If you are familiar with distributed version control systems such as Git, their version
histories are very much like the graph of causal dependencies. Often one commit
happens after another, in a straight line, but sometimes you get branches (when several
people concurrently work on a project), and merges are created when those concurrently
created commits are combined.

Linearizability is stronger than causal consistency
So what is the relationship between the causal order and linearizability? The answer is
that linearizability implies causality: any system that is linearizable will preserve causality
correctly [7]. In particular, if there are multiple communication channels in a
system (such as the message queue and the file storage service in Figure 9-5), linearizability
ensures that causality is automatically preserved without the system having to
do anything special (such as passing around timestamps between different components).

The fact that linearizability ensures causality is what makes linearizable systems simple
to understand and appealing. However, as discussed in “The Cost of Linearizability”
on page 335, making a system linearizable can harm its performance and
availability, especially if the system has significant network delays (for example, if it’s
geographically distributed). For this reason, some distributed data systems have
abandoned linearizability, which allows them to achieve better performance but can
make them difficult to work with.

The good news is that a middle ground is possible. Linearizability is not the only way
of preserving causality—there are other ways too. A system can be causally consistent
without incurring the performance hit of making it linearizable (in particular, the
CAP theorem does not apply). In fact, causal consistency is the strongest possible
consistency model that does not slow down due to network delays, and remains
available in the face of network failures [2, 42].

In many cases, systems that appear to require linearizability in fact only really require
causal consistency, which can be implemented more efficiently. Based on this observation,
researchers are exploring new kinds of databases that preserve causality, with
performance and availability characteristics that are similar to those of eventually
consistent systems [49, 50, 51].

As this research is quite recent, not much of it has yet made its way into production
systems, and there are still challenges to be overcome [52, 53]. However, it is a promising
direction for future systems.

捕获因果依赖 Capturing causal dependencies
In order to determine causal dependencies, we need some way of describing the
“knowledge” of a node in the system. If a node had already seen the value X when it
issued the write Y, then X and Y may be causally related

The techniques for determining which operation happened before which other operation
are similar to what we discussed in “Detecting Concurrent Writes” on page 184.
That section discussed causality in a leaderless datastore, where we need to detect
concurrent writes to the same key in order to prevent lost updates. Causal consistency
goes further: it needs to track causal dependencies across the entire database,
not just for a single key. Version vectors can be generalized to do this [54].

In order to determine the causal ordering, the database needs to know which version
of the data was read by the application. This is why, in Figure 5-13, the version number
from the prior operation is passed back to the database on a write. A similar idea
appears in the conflict detection of SSI, as discussed in “Serializable Snapshot Isolation
(SSI)” on page 261: when a transaction wants to commit, the database checks
whether the version of the data that it read is still up to date. To this end, the database
keeps track of which data has been read by which transaction.

3.2 序列号排序 Sequence Number Ordering
//追踪因果关系不实际
Although causality is an important theoretical concept, actually keeping track of all
causal dependencies can become impractical.

However, there is a better way: we can use sequence numbers or timestamps to order
events. A timestamp need not come from a time-of-day clock (or physical clock,
which have many problems, as discussed in “Unreliable Clocks” on page 287). It can
instead come from a logical clock, which is an algorithm to generate a sequence of
numbers to identify operations, typically using counters that are incremented for
every operation

//要产生与因果关系一致的序列号 
In particular, we can create sequence numbers in a total order that is consistent with
causality

非因果序列号生成器 Noncausal sequence number generators
If there is not a single leader (perhaps because you are using a multi-leader or leaderless
database, or because the database is partitioned), it is less clear how to generate
sequence numbers for operations. Various methods are used in practice:

Each node can generate its own independent set of sequence numbers. For example,
if you have two nodes, one node can generate only odd numbers and the
other only even numbers.

You can attach a timestamp from a time-of-day clock (physical clock) to each
operation [55].

You can preallocate blocks of sequence numbers.

//图，p325 ，根据上下文，Lamport事件解决的是多个leader或无leader的情况，如果只有一个leader，则好结局
Lamport时间戳 Lamport timestamps
Although the three sequence number generators just described are inconsistent with
causality, there is actually a simple method for generating sequence numbers that is
consistent with causality. It is called a Lamport timestamp, proposed in 1978 by Leslie
Lamport [56], in what is now one of the most-cited papers in the field of distributed
systems

The Lamport timestamp is then simply a pair of (counter, node ID).

A Lamport timestamp bears no relationship to a physical time-of-day clock, but it
provides total ordering: if you have two timestamps, the one with a greater counter
value is the greater timestamp; if the counter values are the same, the one with the
greater node ID is the greater timestamp.

So far this description is essentially the same as the even/odd counters described in
the last section. The key idea about Lamport timestamps, which makes them consistent
with causality, is the following: every node and every client keeps track of the
maximum counter value it has seen so far, and includes that maximum on every
request. When a node receives a request or response with a maximum counter value
greater than its own counter value, it immediately increases its own counter to that
maximum.

Lamport timestamps are sometimes confused with version vectors, which we saw in
“Detecting Concurrent Writes” on page 184. Although there are some similarities,
they have a different purpose: version vectors can distinguish whether two operations
are concurrent or whether one is causally dependent on the other, whereas Lamport
timestamps always enforce a total ordering. From the total ordering of Lamport time‐
stamps, you cannot tell whether two operations are concurrent or whether they are
causally dependent. The advantage of Lamport timestamps over version vectors is
that they are more compact.

//（多个leader或无leader的分布式系统中），为了全序排列，需要收集所有节点上的时间戳信息
时间戳排序依然不够 Timestamp ordering is not sufficient 
Although Lamport timestamps define a total order of operations that is consistent
with causality, they are not quite sufficient to solve many common problems in distributed
systems.
For example, consider a system that needs to ensure that a username uniquely identifies
a user account. If two users concurrently try to create an account with the same
username, one of the two should succeed and the other should fail. (We touched on
this problem previously in “The leader and the lock” on page 301.)

At first glance, it seems as though a total ordering of operations (e.g., using Lamport
timestamps) should be sufficient to solve this problem: if two accounts with the same
username are created, pick the one with the lower timestamp as the winner (the one
who grabbed the username first), and let the one with the greater timestamp fail.
Since timestamps are totally ordered, this comparison is always valid.

This approach works for determining the winner after the fact: once you have collected
all the username creation operations in the system, you can compare their timestamps.
However, it is not sufficient when a node has just received a request from a
user to create a username, and needs to decide right now whether the request should
succeed or fail. At that moment, the node does not know whether another node is
concurrently in the process of creating an account with the same username, and what
timestamp that other node may assign to the operation